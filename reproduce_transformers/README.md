## Using this repo to re-implement the various parts of the transformer architecture proposed by Vaswani et al.

1. Work on the encoder
2. Work on the decoder
- both in pytorch. following Havardnlp tutorial -> 
https://nlp.seas.harvard.edu/2018/04/03/attention.html
